{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["dsw3yqel0224","bLT3GuWOC-Z9"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## DRIVE and INSTALL"],"metadata":{"id":"dsw3yqel0224"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/MyDrive/RL/Project\"\n","!pip install -r requirements.txt\n","!pip install --upgrade pillow==6.2.2\n","!pip install -q dm_control>=1.0.9"],"metadata":{"id":"O-0lfiDR0aOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## IMPORT"],"metadata":{"id":"bLT3GuWOC-Z9"}},{"cell_type":"code","source":["#@title Run to install MuJoCo and `dm_control`\n","import distutils.util\n","import subprocess\n","if subprocess.run('nvidia-smi').returncode:\n","  raise RuntimeError(\n","      'Cannot communicate with GPU. '\n","      'Make sure you are using a GPU Colab runtime. '\n","      'Go to the Runtime menu and select Choose runtime type.')\n","\n","print('Installing dm_control...')\n","\n","\n","# Configure dm_control to use the EGL rendering backend (requires GPU)\n","%env MUJOCO_GL=egl\n","\n","!echo Installed dm_control $(pip show dm_control | grep -Po \"(?<=Version: ).+\")\n","#@title All `dm_control` imports required for this tutorial\n","\n","# The basic mujoco wrapper.\n","from dm_control import mujoco\n","\n","# Access to enums and MuJoCo library functions.\n","from dm_control.mujoco.wrapper.mjbindings import enums\n","from dm_control.mujoco.wrapper.mjbindings import mjlib\n","\n","# PyMJCF\n","from dm_control import mjcf\n","\n","# Composer high level imports\n","from dm_control import composer\n","from dm_control.composer.observation import observable\n","from dm_control.composer import variation\n","\n","# Imports for Composer tutorial example\n","from dm_control.composer.variation import distributions\n","from dm_control.composer.variation import noises\n","from dm_control.locomotion.arenas import floors\n","\n","# Control Suite\n","from dm_control import suite\n","\n","# Run through corridor example\n","from dm_control.locomotion.walkers import cmu_humanoid\n","from dm_control.locomotion.arenas import corridors as corridor_arenas\n","from dm_control.locomotion.tasks import corridors as corridor_tasks\n","\n","# Soccer\n","from dm_control.locomotion import soccer\n","\n","# Manipulation\n","from dm_control import manipulation"],"metadata":{"id":"PAgm95y36gyV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671385765927,"user_tz":-60,"elapsed":4508,"user":{"displayName":"Mattia Castelmare","userId":"15170099803029723210"}},"outputId":"792aa9ef-4901-4c7f-b464-08b3b4b85b45","cellView":"form"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 18 17:49:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   76C    P0    35W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Installing dm_control...\n","env: MUJOCO_GL=egl\n","Installed dm_control 1.0.9\n"]}]},{"cell_type":"markdown","source":["## TRAIN"],"metadata":{"id":"lPH9Sl3m01D1"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VDRhpzKezpbM","outputId":"e359af3d-4bcf-417b-b63b-498888b30546","executionInfo":{"status":"error","timestamp":1671386145882,"user_tz":-60,"elapsed":379992,"user":{"displayName":"Mattia Castelmare","userId":"15170099803029723210"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1g-McIVAA4yo7dyxagjsG5olLRqS0vw4T/Project\n"]},{"output_type":"stream","name":"stderr","text":["tcmalloc: large alloc 23040000000 bytes == 0x7efc62b58000 @  0x7f02904541e7 0x7f0282968994 0x7f028296912f 0x7f02829c78f5 0x7f02829c92cb 0x7f0282a673ab 0x5aae14 0x49abe4 0x7f02879e4807 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x7f02879e4807 0x5d8868 0x4990ca 0x7f02879e4807 0x55cd91 0x55d743 0x627376 0x5aaeb9 0x4990ca 0x7f02879e4807 0x4f6097 0x562426 0x7f02879e4807 0x4f6097 0x562426 0x7f02879e4807\n","tcmalloc: large alloc 23040000000 bytes == 0x7ef7056b0000 @  0x7f02904541e7 0x7f0282968994 0x7f028296912f 0x7f02829c78f5 0x7f02829c92cb 0x7f0282a673ab 0x5aae14 0x49abe4 0x7f02879e4807 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x7f02879e4807 0x5d8868 0x4990ca 0x7f02879e4807 0x55cd91 0x55d743 0x627376 0x5aaeb9 0x4990ca 0x7f02879e4807 0x4f6097 0x562426 0x7f02879e4807 0x4f6097 0x562426 0x7f02879e4807\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[32meval\u001b[0m | S: 0 | ER: 0.0000\n","| \u001b[33mtrain\u001b[0m | E: 1 | S: 1000 | D: 243.7 s | R: 0.0000 | BR: 0.0000 | ALOSS: 0.0000 | CLOSS: 0.0000 | RLOSS: 0.0000\n","| \u001b[32meval\u001b[0m | S: 1000 | ER: 293.0000\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 177\u001b[0m\n\u001b[1;32m    172\u001b[0m         episode_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[2], line 157\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m     num_updates \u001b[38;5;241m=\u001b[39m init_steps \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m init_steps \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_updates):\n\u001b[0;32m--> 157\u001b[0m         \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m time_step \u001b[38;5;241m=\u001b[39m env_\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    160\u001b[0m reward \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mreward\n","File \u001b[0;32m/content/drive/.shortcut-targets-by-id/1g-McIVAA4yo7dyxagjsG5olLRqS0vw4T/Project/agent.py:61\u001b[0m, in \u001b[0;36mAgent.update\u001b[0;34m(self, replay_buffer, step)\u001b[0m\n\u001b[1;32m     57\u001b[0m done \u001b[38;5;241m=\u001b[39m dones\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     59\u001b[0m max_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(re)\n\u001b[0;32m---> 61\u001b[0m q, ri, contrastive_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_reward_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_reward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m ri \u001b[38;5;241m=\u001b[39m ri\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m reward \u001b[38;5;241m=\u001b[39m re \u001b[38;5;241m+\u001b[39m ri\n","File \u001b[0;32m/content/drive/.shortcut-targets-by-id/1g-McIVAA4yo7dyxagjsG5olLRqS0vw4T/Project/encoder.py:158\u001b[0m, in \u001b[0;36mFeatureEncoder.encode_reward_loss\u001b[0;34m(self, s, a, sp, step, max_reward, sim_metric)\u001b[0m\n\u001b[1;32m    156\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(s, grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# encode state with key encoder with grad\u001b[39;00m\n\u001b[1;32m    157\u001b[0m                               \u001b[38;5;66;03m# in order to update the network through SAC loss\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m ae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    160\u001b[0m qp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfdm(torch\u001b[38;5;241m.\u001b[39mcat((q,ae),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# predict new state\u001b[39;00m\n\u001b[1;32m    162\u001b[0m kp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(sp, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# encode keys with target\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"]}],"source":["%cd \"/content/drive/MyDrive/RL/Project\"\n","import numpy as np\n","import torch\n","import argparse\n","import os\n","import math\n","import gym\n","import sys\n","import random\n","import time\n","import json\n","\n","import copy\n","from dm_control import suite\n","from dm_control.suite.wrappers import pixels\n","import utils\n","\n","from logger import Logger\n","from video import VideoRecorder\n","\n","from agent import Agent\n","\n","\n","seed = 1\n","domain_name = \"ball_in_cup\"\n","task_name = \"catch\"\n","image_size = 84\n","action_repeat = 1\n","frame_stack = 3\n","work_dir = '/content/drive/MyDrive/RL/Project'\n","save_video = False\n","\n","replay_buffer_capacity = 100000\n","batch_size = 32\n","\n","s_dim = 128\n","a_dim = 50\n","\n","num_train_steps = 1000000\n","\n","init_steps = 1000\n","\n","save_model = True\n","save_buffer = True\n","\n","num_eval_episodes = 10\n","eval_frequency = 1000\n","\n","\n","def evaluate(env, agent, video, num_episodes, L, step):\n","    for i in range(num_episodes):\n","        obs = env.reset()\n","        \n","        video.init(enabled=(i == 0))\n","        done = False\n","        episode_reward = 0\n","        while not done: \n","            with utils.eval_mode(agent):\n","              \n","              action = agent.select_action(obs.observation['pixels'])\n","                \n","            time_step = env.step(action)\n","            reward = time_step.reward\n","            done = time_step.last()\n","            video.record(env)\n","            episode_reward += reward\n","\n","        video.save('%d.mp4' % step)\n","        L.log('eval/episode_reward', episode_reward, step)\n","    L.dump(step)\n","\n","def main():\n","    utils.set_seed_everywhere(seed)\n","\n","    env_ = pixels.Wrapper(suite.load(\n","        domain_name=domain_name,\n","        task_name=task_name\n","    ))\n","\n","    # stack several consecutive frames together\n","\n","    env = utils.FrameStack(env_, k=frame_stack)\n","    s = env.reset()\n","    s = np.delete(s, np.s_[:480], axis=0)\n","\n","    \n","    utils.make_dir(work_dir)\n","    video_dir = utils.make_dir(os.path.join(work_dir, 'video'))\n","    model_dir = utils.make_dir(os.path.join(work_dir, 'model'))\n","    buffer_dir = utils.make_dir(os.path.join(work_dir, 'buffer'))\n","\n","    video = VideoRecorder(video_dir if save_video else None)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  \n","    replay_buffer = utils.ReplayBuffer(\n","        obs_shape=s.shape,\n","        action_shape=env.action_spec().shape,\n","        capacity=replay_buffer_capacity,\n","        batch_size=batch_size,\n","        device=device\n","    )\n","    \n","    agent = Agent(\n","        obs_shape=np.transpose(s).shape,\n","        a_shape=env.action_spec().shape,\n","        s_dim = s_dim,\n","        a_dim = a_dim,\n","        device=device\n","    )\n","\n","    L = Logger(work_dir, use_tb=False)\n","\n","    episode, episode_reward, done = 0, 0, True\n","    start_time = time.time()\n","    for step in range(num_train_steps):\n","        \n","        if done:\n","            if step > 0:\n","                L.log('train/duration', time.time() - start_time, step)\n","                start_time = time.time()\n","                L.dump(step)\n","\n","            # evaluate agent periodically\n","            if step % eval_frequency == 0:\n","                L.log('eval/episode', episode, step)\n","                evaluate(env_, agent, video, num_eval_episodes, L, step)\n","                if save_model:\n","                    agent.save(model_dir, step)\n","                if save_buffer:\n","                    replay_buffer.save(buffer_dir)\n","\n","            L.log('train/episode_reward', episode_reward, step)\n","            \n","            \n","            obs = env_.reset()\n","            obs = obs.observation['pixels']\n","            done = False\n","            episode_reward = 0\n","            episode_step = 0\n","            episode += 1\n","\n","            L.log('train/episode', episode, step)\n","\n","        # sample action for data collection\n","        if step < init_steps:\n","            spec = env.action_spec()\n","            action = np.random.uniform(spec.minimum,spec.maximum,spec.shape)\n","        else:\n","            with utils.eval_mode(agent): \n","                action = agent.sample_action(obs)\n","\n","        # run training update\n","        if step >= init_steps:\n","            num_updates = init_steps if step == init_steps else 1\n","            for _ in range(num_updates):\n","                agent.update(replay_buffer, step)\n","\n","        time_step = env_.step(action)\n","        reward = time_step.reward\n","        next_obs = time_step.observation['pixels']\n","        done = time_step.last()\n","        # allow infinit bootstrap\n","        done_bool = 0 if episode_step + 1 == env._max_episode_steps else float(\n","            done\n","        )\n","        episode_reward += reward\n","\n","        replay_buffer.add(obs, action, reward, next_obs, done_bool)\n","       \n","        obs = next_obs\n","        episode_step += 1\n","\n","      \n","if __name__ == '__main__':\n","    \n","    main()\n","\n"]},{"cell_type":"markdown","source":["## IMPORT"],"metadata":{"id":"KLpS_FnaToF-"}},{"cell_type":"code","source":["from dm_control import suite\n","from dm_control.suite.wrappers import pixels\n","\n","env = pixels.Wrapper(suite . load ( \"ball_in_cup\" , \"catch\" ))\n","\n","s = env.reset()\n","d = s.observation['pixels']\n","def reshape_(x):\n","  return x.reshape((x[0] * 3,) + x[1:])"],"metadata":{"id":"-oUHGzSZ6iGK","executionInfo":{"status":"ok","timestamp":1671379781697,"user_tz":-60,"elapsed":546,"user":{"displayName":"Mattia Castelmare","userId":"15170099803029723210"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(d.shape, type(d))"],"metadata":{"id":"oqoryD1KrRum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = torch.Tensor(1,40,40,3)\n","print(a.transpose(3,1).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfnO-FgKSU7V","executionInfo":{"status":"ok","timestamp":1671384726363,"user_tz":-60,"elapsed":21,"user":{"displayName":"Mattia Castelmare","userId":"15170099803029723210"}},"outputId":"ef3d2353-ad47-4468-ae3f-b77d6717dbee"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3, 40, 40])\n"]}]}]}